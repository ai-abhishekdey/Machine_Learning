{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cba2473",
   "metadata": {},
   "source": [
    "## MLFLOW Experimentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f782d3c1",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3efbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"glass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47becb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9939d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=[\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66193ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce2b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df[\"Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d685692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271480fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 9) (214,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729768ff",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6829c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c65bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 9) (43, 9)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339354c8",
   "metadata": {},
   "source": [
    "### Standardise Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b7baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf43e0",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2501c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7441860465116279, 'precision': 0.7126937984496123, 'recall': 0.7441860465116279, 'f1_score': 0.7266316579144787}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'logistic_reg_model' already exists. Creating a new version of this model...\n",
      "2025/10/04 22:49:27 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_reg_model, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run3_logistic_reg at: http://127.0.0.1:5000/#/experiments/222058835319637488/runs/9693dcb2fe89498f8e519c3beca29b6e\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/222058835319637488\n",
      "✅ run3_logistic_reg completed. Run ID: 9693dcb2fe89498f8e519c3beca29b6e, Artifact path: logistic_reg_3\n",
      "✅ Model registered as 'logistic_reg_model' in MLflow Model Registry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'logistic_reg_model'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ===== Set MLflow tracking URI =====\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# ===== Single experiment for all models =====\n",
    "experiment_name = \"ML_Model_Experiments\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# ===== Determine next run number for Logistic Regression =====\n",
    "runs = client.search_runs([experiment_id], filter_string=\"tags.model_type='logistic_reg'\")\n",
    "next_id = len(runs) + 1\n",
    "\n",
    "# ===== Model training =====\n",
    "params = {\"max_iter\": 100, \"C\": 0.5, \"solver\": \"saga\"}\n",
    "model = LogisticRegression(**params)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# ===== Evaluation =====\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": acc,\n",
    "    \"precision\": prec,\n",
    "    \"recall\": rec,\n",
    "    \"f1_score\": f1\n",
    "}\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "# ===== MLflow Logging & Register Model =====\n",
    "run_name = f\"run{next_id}_logistic_reg\"\n",
    "artifact_path = f\"logistic_reg_{next_id}\"\n",
    "model_registry_name = f\"logistic_reg_model\"  # name in MLflow Model Registry\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.set_tag(\"model_type\", \"logistic_reg\")\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Log and register the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name=artifact_path,\n",
    "        registered_model_name=model_registry_name,\n",
    "        input_example=x_test[:5]\n",
    "    )\n",
    "\n",
    "print(f\"✅ {run_name} completed. Run ID: {run.info.run_id}, Artifact path: {artifact_path}\")\n",
    "print(f\"✅ Model registered as '{model_registry_name}' in MLflow Model Registry\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8a140",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf7a774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8372093023255814, 'precision': 0.8542214739205162, 'recall': 0.8372093023255814, 'f1_score': 0.835526738827564}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'random_forest_model' already exists. Creating a new version of this model...\n",
      "2025/10/04 22:47:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_model, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run2_random_forest at: http://127.0.0.1:5000/#/experiments/222058835319637488/runs/b8b07cb2f207450e83158efd00ce42e3\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/222058835319637488\n",
      "✅ run2_random_forest completed. Run ID: b8b07cb2f207450e83158efd00ce42e3, Artifact path: random_forest_2\n",
      "✅ Model registered as 'random_forest_model' in MLflow Model Registry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'random_forest_model'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ===== Set MLflow tracking URI =====\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# ===== Single experiment for all models =====\n",
    "experiment_name = \"ML_Model_Experiments\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# ===== Determine next run number for Random Forest =====\n",
    "runs = client.search_runs([experiment_id], filter_string=\"tags.model_type='random_forest'\")\n",
    "next_id = len(runs) + 1\n",
    "\n",
    "# ===== Model training =====\n",
    "params = {\"n_estimators\": 120, \"max_depth\": None, \"random_state\": 42}\n",
    "model = RandomForestClassifier(**params)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# ===== Evaluation =====\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": acc,\n",
    "    \"precision\": prec,\n",
    "    \"recall\": rec,\n",
    "    \"f1_score\": f1\n",
    "}\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "# ===== MLflow Logging & Register Model =====\n",
    "run_name = f\"run{next_id}_random_forest\"\n",
    "artifact_path = f\"random_forest_{next_id}\"\n",
    "model_registry_name = \"random_forest_model\"  # MLflow Model Registry name\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.set_tag(\"model_type\", \"random_forest\")\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Log and register the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name=artifact_path,\n",
    "        registered_model_name=model_registry_name,\n",
    "        input_example=x_test[:5]\n",
    "    )\n",
    "\n",
    "print(f\"✅ {run_name} completed. Run ID: {run.info.run_id}, Artifact path: {artifact_path}\")\n",
    "print(f\"✅ Model registered as '{model_registry_name}' in MLflow Model Registry\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08fd2a",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc750f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6744186046511628, 'precision': 0.6324750830564784, 'recall': 0.6744186046511628, 'f1_score': 0.6330514446793516}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'svm_model' already exists. Creating a new version of this model...\n",
      "2025/10/04 22:52:33 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: svm_model, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run2_svm at: http://127.0.0.1:5000/#/experiments/222058835319637488/runs/1017d22d9d8e4d11856d9992d4de49f5\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/222058835319637488\n",
      "✅ run2_svm completed. Run ID: 1017d22d9d8e4d11856d9992d4de49f5, Artifact path: svm_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'svm_model'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ===== Set MLflow tracking URI =====\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# ===== Single experiment =====\n",
    "experiment_name = \"ML_Model_Experiments\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# ===== Determine next run number for SVM =====\n",
    "runs = client.search_runs([experiment_id], filter_string=\"tags.model_type='svm'\")\n",
    "next_id = len(runs) + 1\n",
    "\n",
    "# ===== Label encoding for multi-class =====\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# ===== Model training =====\n",
    "params = {\"C\": 0.5, \"kernel\": \"rbf\", \"probability\": True, \"random_state\": 42}\n",
    "model = SVC(**params)\n",
    "model.fit(x_train, y_train_encoded)\n",
    "y_pred_encoded = model.predict(x_test)\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# ===== Evaluation =====\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='weighted',zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, average='weighted',zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted',zero_division=0)\n",
    "metrics = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1}\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "# ===== MLflow Logging & Register Model =====\n",
    "run_name = f\"run{next_id}_svm\"\n",
    "artifact_path = f\"svm_{next_id}\"\n",
    "model_registry_name = \"svm_model\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.set_tag(\"model_type\", \"svm\")\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name=artifact_path,\n",
    "        registered_model_name=model_registry_name,\n",
    "        input_example=x_test[:5]\n",
    "    )\n",
    "\n",
    "print(f\"✅ {run_name} completed. Run ID: {run.info.run_id}, Artifact path: {artifact_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af47a97",
   "metadata": {},
   "source": [
    "### Naive Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c5c38dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5116279069767442, 'precision': 0.47674418604651164, 'recall': 0.5116279069767442, 'f1_score': 0.45059159526723785}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'naive_bayes_model' already exists. Creating a new version of this model...\n",
      "2025/10/04 22:53:50 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: naive_bayes_model, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run2_naive_bayes at: http://127.0.0.1:5000/#/experiments/222058835319637488/runs/1c96e30d578d49eb8f8f2f5520d67892\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/222058835319637488\n",
      "✅ run2_naive_bayes completed. Run ID: 1c96e30d578d49eb8f8f2f5520d67892, Artifact path: naive_bayes_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'naive_bayes_model'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ===== Set MLflow tracking URI =====\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# ===== Single experiment =====\n",
    "experiment_name = \"ML_Model_Experiments\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# ===== Determine next run number for Naive Bayes =====\n",
    "runs = client.search_runs([experiment_id], filter_string=\"tags.model_type='naive_bayes'\")\n",
    "next_id = len(runs) + 1\n",
    "\n",
    "# ===== Model training =====\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# ===== Evaluation =====\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "metrics = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1}\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "# ===== MLflow Logging & Register Model =====\n",
    "run_name = f\"run{next_id}_naive_bayes\"\n",
    "artifact_path = f\"naive_bayes_{next_id}\"\n",
    "model_registry_name = \"naive_bayes_model\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.set_tag(\"model_type\", \"naive_bayes\")\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name=artifact_path,\n",
    "        registered_model_name=model_registry_name,\n",
    "        input_example=x_test[:5]\n",
    "    )\n",
    "\n",
    "print(f\"✅ {run_name} completed. Run ID: {run.info.run_id}, Artifact path: {artifact_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1880e",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e52b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7906976744186046, 'precision': 0.7972868217054263, 'recall': 0.7906976744186046, 'f1_score': 0.7876452692811955}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'xgboost_model' already exists. Creating a new version of this model...\n",
      "2025/10/04 22:56:47 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_model, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run3_xgboost at: http://127.0.0.1:5000/#/experiments/222058835319637488/runs/c0c4c5314d5d4e7482ee9b0417230304\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/222058835319637488\n",
      "✅ run3_xgboost completed. Run ID: c0c4c5314d5d4e7482ee9b0417230304, Artifact path: xgboost_3\n",
      "✅ Model registered as 'xgboost_model' in MLflow Model Registry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'xgboost_model'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ===== Set MLflow tracking URI =====\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# ===== Single experiment =====\n",
    "experiment_name = \"ML_Model_Experiments\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# ===== Determine next run number for XGBoost =====\n",
    "runs = client.search_runs([experiment_id], filter_string=\"tags.model_type='xgboost'\")\n",
    "next_id = len(runs) + 1\n",
    "\n",
    "# ===== Label encoding for multi-class =====\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# ===== Model training =====\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 12,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"gamma\": 0,\n",
    "    \"reg_alpha\": 0,\n",
    "    \"reg_lambda\": 1,\n",
    "    \"random_state\": 42,\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"eval_metric\": \"mlogloss\"\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(x_train, y_train_encoded)\n",
    "y_pred_encoded = model.predict(x_test)\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# ===== Evaluation =====\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "metrics = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1}\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "# ===== MLflow Logging & Register Model =====\n",
    "run_name = f\"run{next_id}_xgboost\"\n",
    "artifact_path = f\"xgboost_{next_id}\"\n",
    "model_registry_name = \"xgboost_model\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.set_tag(\"model_type\", \"xgboost\")\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name=artifact_path,\n",
    "        registered_model_name=model_registry_name,\n",
    "        input_example=x_test[:5]\n",
    "    )\n",
    "\n",
    "print(f\"✅ {run_name} completed. Run ID: {run.info.run_id}, Artifact path: {artifact_path}\")\n",
    "print(f\"✅ Model registered as '{model_registry_name}' in MLflow Model Registry\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90602e",
   "metadata": {},
   "source": [
    "## Find out the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b03da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: b8b07cb2f207450e83158efd00ce42e3\n",
      "Run Name: run2_random_forest\n",
      "Model Type: random_forest\n",
      "Accuracy: 0.8372093023255814\n",
      "F1-score: 0.835526738827564\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: e0706a2d9a954568a034455a1492e9fd\n",
      "Run Name: run1_random_forest\n",
      "Model Type: random_forest\n",
      "Accuracy: 0.8372093023255814\n",
      "F1-score: 0.835526738827564\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: c0c4c5314d5d4e7482ee9b0417230304\n",
      "Run Name: run3_xgboost\n",
      "Model Type: xgboost\n",
      "Accuracy: 0.7906976744186046\n",
      "F1-score: 0.7876452692811955\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: 3cd11d0c866447308707a5b426cb805d\n",
      "Run Name: run2_xgboost\n",
      "Model Type: xgboost\n",
      "Accuracy: 0.7906976744186046\n",
      "F1-score: 0.7876452692811955\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: b4da6b67db6f4082a54b6ff0b834696c\n",
      "Run Name: run1_xgboost\n",
      "Model Type: xgboost\n",
      "Accuracy: 0.7906976744186046\n",
      "F1-score: 0.7876452692811955\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: 9693dcb2fe89498f8e519c3beca29b6e\n",
      "Run Name: run3_logistic_reg\n",
      "Model Type: logistic_reg\n",
      "Accuracy: 0.7441860465116279\n",
      "F1-score: 0.7266316579144787\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: 39c0c788151642539a9ce6e352f67a40\n",
      "Run Name: run2_logistic_reg\n",
      "Model Type: logistic_reg\n",
      "Accuracy: 0.7441860465116279\n",
      "F1-score: 0.7266316579144787\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: a08a938454cb405c95e9708003fbe884\n",
      "Run Name: run1_logistic_reg\n",
      "Model Type: logistic_reg\n",
      "Accuracy: 0.7441860465116279\n",
      "F1-score: 0.7266316579144787\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: d323f833e47e4a709288dd973c876e75\n",
      "Run Name: run1_svm\n",
      "Model Type: svm\n",
      "Accuracy: 0.7209302325581395\n",
      "F1-score: 0.6941927789639718\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: 1017d22d9d8e4d11856d9992d4de49f5\n",
      "Run Name: run2_svm\n",
      "Model Type: svm\n",
      "Accuracy: 0.6744186046511628\n",
      "F1-score: 0.6330514446793516\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: 1c96e30d578d49eb8f8f2f5520d67892\n",
      "Run Name: run2_naive_bayes\n",
      "Model Type: naive_bayes\n",
      "Accuracy: 0.5116279069767442\n",
      "F1-score: 0.45059159526723785\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Run ID: e0fc329a232345e48aac3249000e4064\n",
      "Run Name: run1_naive_bayes\n",
      "Model Type: naive_bayes\n",
      "Accuracy: 0.5116279069767442\n",
      "F1-score: 0.45059159526723785\n",
      "Artifact Path: N/A\n",
      "------\n",
      "Best Model: random_forest\n",
      "Run ID: b8b07cb2f207450e83158efd00ce42e3\n",
      "Run Name: run2_random_forest\n",
      "Accuracy: 0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_name = \"ML_Model_Experiments\"\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Get all runs\n",
    "runs = client.search_runs([experiment_id], order_by=[\"metrics.accuracy DESC\"])  # highest accuracy first\n",
    "\n",
    "# Print summary\n",
    "for r in runs:\n",
    "    print(f\"Run ID: {r.info.run_id}\")\n",
    "    print(f\"Run Name: {r.info.run_name}\")\n",
    "    print(f\"Model Type: {r.data.tags.get('model_type')}\")\n",
    "    print(f\"Accuracy: {r.data.metrics.get('accuracy')}\")\n",
    "    print(f\"F1-score: {r.data.metrics.get('f1_score')}\")\n",
    "    print(f\"Artifact Path: {r.data.tags.get('mlflow.log-model.history', 'N/A')}\")\n",
    "    print(\"------\")\n",
    "\n",
    "# Extracting the best run\n",
    "\n",
    "best_run = runs[0]\n",
    "best_model_type = best_run.data.tags.get(\"model_type\")\n",
    "best_run_id = best_run.info.run_id\n",
    "best_run_name = best_run.info.run_name\n",
    "best_accuracy = best_run.data.metrics.get(\"accuracy\")\n",
    "\n",
    "print(f\"Best Model: {best_model_type}\")\n",
    "print(f\"Run ID: {best_run_id}\")\n",
    "print(f\"Run Name: {best_run_name}\")\n",
    "print(f\"Accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a066ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
